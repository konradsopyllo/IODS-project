---
output:
  html_document: default
  pdf_document: default
---
# Assignment 2

- Describe your work and results clearly. 
- Assume the reader has an introductory course level understanding of writing and reading R code as well as statistical methods.
- Assume the reader has no previous knowledge of your data or the more advanced methods you are using.

Konrad Sopyllo

The data presented below is based on a survey and the data was collected 3.12.2014 - 10.1.2015 in Florence,Italy. The data was translated in Finnish by Kimmo Vehkalahti and Liisa Myyry. The survey was based originally on a finnish study concerning the progress and satisfaction related to the double phased study programme in technical universities. 

#Data wrangling

#In this data wrangling part we will focus brielfy on creating the data set as in the csv-file in the data-folder. 

```{r}

library(tidyverse)

url<-"http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt"
data=read_tsv(url)

```

#Creating an analysis_dataset with the variables gender, age, attitude, deep, stra, surf and points by combining the values in the learning2014 data. Note that Stra, surf and deep consist of multiple variables.

```{r}
collumns <- c("gender", "Age", "Attitude", "Points")

analysis_dataset <- data[collumns]
```

Other variables explained:

d_sm     Seeking Meaning          
d_ri     Relating Ideas           
d_ue     Use of Evidence          
su_lp    Lack of Purpose           
su_um    Unrelated Memorising     
su_sb    Syllabus-boundness        
st_os    Organized Studying        
st_tm    Time Management          
Deep     Deep approach           
Surf     Surface approach          
Stra     Strategic approach        

#Stra =  st_os+st_tm = ST01+ST09+ST17+ST25+ST04+ST12+ST20+ST28
```{r}
stra_collumns = unlist(str_split(c("ST01+ST09+ST17+ST25+ST04+ST12+ST20+ST28"), "\\+"))
```

#surf = su_lp+su_um+su_sb = SU02+SU10+SU18+SU26 + SU05+SU13+SU21+SU29 + SU08+SU16+SU24+SU32
```{r}
surf_collumns = unlist(str_split(c("SU02+SU10+SU18+SU26+SU05+SU13+SU21+SU29+SU08+SU16+SU24+SU32"), "\\+"))
```

#deep = d_sm+d_ri+d_ue = D03+D11+D19+D27 + D07+D14+D22+D30 + D06+D15+D23+D31
```{r}
deep_collumns = unlist(str_split(c("D03+D11+D19+D27+D07+D14+D22+D30+D06+D15+D23+D31"), "\\+"))
```


#Adding stra, deep and surf by creating scaled variables using rowMeans-function. 
```{r}
analysis_dataset["stra"] = rowMeans(select(data, one_of(stra_collumns)))
analysis_dataset["deep"] = rowMeans(select(data, one_of(deep_collumns)))
analysis_dataset["surf"] = rowMeans(select(data, one_of(surf_collumns)))
```


#filtering out rows where Points variable = 0
```{r}
analysis_dataset = analysis_dataset[analysis_dataset$Points != 0,]
dim(analysis_dataset)

```

#As in the exercise provided the file has 166 observations and 7 variables

#Saving the analysis_dataset as a csv-file
```{r}

library(readr)
write_csv(analysis_dataset, "data/learning2014.csv")

```

#Showing how to read the csv-file

```{r}
loaded_data <- read_csv("data/learning2014.csv")
str(loaded_data)
head(loaded_data)
```

##Data analysis

In this section we will focus further on analysing the data itself. The brief description of the contents of the data have been presented in the beginning of the file. 

#Creating the correlation matrix

```{r}

library("Hmisc")
library("corrplot")
library(ggplot2)
```

#Gender correlation
```{r}
gender_graph <- ggplot(data.frame(analysis_dataset), aes(x = gender)) +
  geom_bar(fill = "lightgreen")
print(gender_graph)
```

#Points correlation
```{r}
points_dist <- ggplot(data.frame(analysis_dataset), aes(x =Points)) +
  geom_density(fill = "lightgreen")
print(points_dist)
```

#Age correlation
```{r}
age_dist <- points_dist <- ggplot(data.frame(analysis_dataset), aes(x = Age)) +
  geom_density(fill = "lightgreen")
print(points_dist)
```

#deep correlation
```{r}
deep_dist <- ggplot(data.frame(analysis_dataset), aes(x = deep)) +
  geom_density(fill = "lightgreen")
print(deep_dist)
```

#surf correlation
```{r}
surf_dist <- ggplot(data.frame(analysis_dataset), aes(x = surf)) +
  geom_density(fill = "lightgreen")
print(surf_dist)
```

#stra correlation
```{r}
stra_dist <- ggplot(data.frame(analysis_dataset), aes(x = stra)) +
  geom_density(fill = "lightgreen")
print(stra_dist)
```


#Creating a correlation graph of variables:"Attitude","deep","stra","surf","Points" using Pearson
```{r}
correlations = c("Attitude","deep","stra","surf","Points")
analysis_cor = cor(analysis_dataset[correlations])
corrplot(analysis_cor)


plot(analysis_dataset)

```

#By having a look at the correlation analysis we can identify the factors with the highest correspondance. Those will be further explained below.


##Attitude vs Points
```{r}
p1 <- ggplot(data.frame(analysis_dataset), aes(x = Attitude, y = Points))
p2 <- p1 + geom_point()
p3 <- p2 + geom_smooth(method = "lm")
p4 <- p3+ggtitle("Attitude vs Points")
print(p4)


model <- lm(analysis_dataset$Points~analysis_dataset$Attitude)
summary(model)
```

#p-value being lowest in this correlation graph.

#Other way of doing the same thing
```{r}

library(ggplot2)
qplot(Attitude, Points, data = analysis_dataset) + geom_smooth(method = "lm")
my_model <- lm(Points ~ Attitude, data = analysis_dataset)

```

#surf vs deep 

```{r}
p1 <- ggplot(data.frame(analysis_dataset), aes(x = deep, y = surf))
p2 <- p1 + geom_point()
p3 <- p2 + geom_smooth(method = "lm")
p4 <- p3+ggtitle("deep vs surf")
print(p4)

model <- lm(analysis_dataset$surf~analysis_dataset$deep)
summary(model)

```
#p-value being second lowest in this comparison

#Attitude vs surf
```{r}
p1 <- ggplot(data.frame(analysis_dataset), aes(x = Attitude, y = surf))
p2 <- p1 + geom_point()
p3 <- p2 + geom_smooth(method = "lm")
p4 <- p3+ggtitle("Attitude vs surf")
print(p4)

model <- lm(analysis_dataset$surf~analysis_dataset$Attitude)
summary(model)
```
#p-value being third lowest in this comparison.
The abovementioned three statistical models (Attitude vs surf, surf vs deep, Attitude vs Points) show a rather significant coefficient. In the linear model especially Attitude (predictor variable) vs Points (response variable) have a statistically strong correlation.

#Creating a multiple variable model 
```{r}

library(GGally)
library(ggplot2)
ggpairs(analysis_dataset, lower = list(combo = wrap("facethist", bins = 20)))
my_model2 <- lm(Points ~ Attitude + stra, data = analysis_dataset)
summary(my_model2)

my_model2 <- lm(Points ~ Attitude + stra, data = analysis_dataset)


```
#Linear model with multiple variables 
```{r}
lm(my_model2)

par(mfrow = c(2, 2))
```
#Residuals vs Fitted values (which = 1)
```{r}
plot(my_model2, which = 1)
```
#Normal QQ-plot (which = 2)
```{r}
plot(my_model2, which = 2)
```
#Residuals vs Leverage (which = 5)
```{r}
plot(my_model2, which = 5)
```

#Multiple explanatory variables all in one
```{r}
plot(my_model2, which = c(1, 2, 5))
```
In the Residual vs Fitted plot the points are fairly randomly scattered and follow the line. It suggest the assumption is reasonable. In the QQ plot there is some deviation from the norm indicating departure from normality. Residuals vs Leverage on the other hand shows a uneven distribution suggesting heteroscedasticity.

#Making predictions

```{r}
m <- lm(Points ~ Attitude, data = analysis_dataset)
summary(m)
```
As we can se above the Adjusted R-squared is  0.1856. This is not a sign of a good model.

#New observations
```{r}
new_attitudes <- c("Mia" = 3.8, "Mike"= 4.4, "Riikka" = 2.2, "Pekka" = 2.9)
new_data <- data.frame(Attitude = new_attitudes)
print(new_data)

```

#Predicting exam points based on the model created above.
```{r}
predictions <- predict(m, newdata = new_data)
print(predictions)
```


Here we go again...
